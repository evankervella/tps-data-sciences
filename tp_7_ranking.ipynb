{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to rank on Microsoft Learning to Rank Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from os.path import expanduser, join\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a NumPy array version of Fold1 of the [MSLR-WEB10K](http://research.microsoft.com/en-us/projects/mslr/) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data from file...\n",
      "Number of query ID 723412\n",
      "Reading training data from file...\n",
      "Number of query ID 241521\n",
      "CPU times: user 1min 35s, sys: 2.16 s, total: 1min 37s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import scipy.sparse\n",
    "\"\"\"sparse_matrix = scipy.sparse.csc_matrix\n",
    "\"\"\"\n",
    "\n",
    "xrange = range\n",
    "\n",
    "# Functions to extrac the documents, query and rank information\n",
    "def extractFeatures(split):\n",
    "    features = []\n",
    "    for i in xrange(2, 138):\n",
    "        features.append(float(split[i].split(':')[1]))\n",
    "    # Convert to tuples:\n",
    "    return features\n",
    "\n",
    "def extractQueryData(split):\n",
    "    # Add tuples:\n",
    "    queryFeatures = split[1].split(':')[1]\n",
    "    return queryFeatures\n",
    "\n",
    "def readDataset(path):\n",
    "    print('Reading training data from file...')\n",
    "    with open(path, 'r') as file:\n",
    "        #k=0\n",
    "        features_list=[]\n",
    "        rank_list=[]\n",
    "        query_list=[]\n",
    "        for line in file:\n",
    "            split = line.split()\n",
    "            features_list.append(extractFeatures(split))\n",
    "            rank_list.append(int(split[0]))\n",
    "            query_list.append(extractQueryData(split))\n",
    "            #k+=1\n",
    "            #if k==100:\n",
    "            #    break\n",
    "    print('Number of query ID %d' %(len(features_list)))\n",
    "    return features_list,rank_list,query_list\n",
    "\n",
    "\n",
    "X_train, y_train, qid_train = readDataset('datas/train.txt')\n",
    "\n",
    "X_test, y_test, qid_test = readDataset('datas/test.txt')\n",
    "\n",
    "\n",
    "\"\"\"X_train, y_train, qid_train = data['X_train'], data['y_train'], data['qid_train']\n",
    "X_vali, y_vali, qid_vali = data['X_vali'], data['y_vali'], data['qid_vali']\n",
    "X_test, y_test, qid_test = data['X_test'], data['y_test'], data['qid_test']\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data from file...\n",
      "Number of query ID 235259\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_valid, y_valid, qid_valid = readDataset('datas/vali.txt')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print (X_train[0])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print (y_train[0], Id_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "qid_train  = np.asarray(qid_train)\n",
    "\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "qid_test  = np.asarray(qid_test)\n",
    "\n",
    "X_valid = np.asarray(X_valid)\n",
    "y_valid = np.asarray(y_valid)\n",
    "qid_valid  = np.asarray(qid_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total size in bytes, total number of search results and number of queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200192"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train) + len(X_valid) + len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(qid_train)) + len(np.unique(qid_valid)) + len(np.unique(qid_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the training and validation sets as a big development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = np.vstack([X_train, X_valid])\n",
    "y_dev = np.concatenate([y_train, y_valid])\n",
    "qid_dev = np.concatenate([qid_train, qid_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(958671, 136)\n",
      "(723412,)\n"
     ]
    }
   ],
   "source": [
    "print(X_dev.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract a subset of 500 queries to speed up the learning when prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "def subsample(X, y, qid, size, seed=None):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    unique_qid = np.unique(qid)\n",
    "    qid_mask = rng.permutation(len(unique_qid))[:size]\n",
    "    subset_mask = np.in1d(qid_train, unique_qid[qid_mask])\n",
    "    print(subset_mask)\n",
    "    a =  y[subset_mask]\n",
    "    return X[subset_mask,:],a, qid[subset_mask]\n",
    "\n",
    "\n",
    "X_train_small, y_train_small, qid_train_small = subsample(\n",
    "    X_train, y_train, qid_train, 500, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62655, 136)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(qid_train_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "X_train_medium, y_train_medium, qid_train_medium = subsample(\n",
    "    X_train, y_train, qid_train, 1000, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_irrelevant(X, y, qid, seed=None):\n",
    "    \"\"\"Subsample the zero-scored entries\"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    unique_qid = np.unique(qid)\n",
    "    final_mask = np.ones(shape=y.shape, dtype=np.bool)\n",
    "    for this_qid in unique_qid:\n",
    "        this_mask = qid == this_qid\n",
    "        this_y = y[this_mask]\n",
    "        relevant = this_y >= 2\n",
    "        ratio = float(np.mean(relevant))\n",
    "        if ratio > 0.5:\n",
    "            # already balanced\n",
    "            continue\n",
    "            \n",
    "        final_mask[this_mask] = np.logical_or(\n",
    "            relevant, np.random.random(len(this_y)) > 0.7) \n",
    "    return X[final_mask], y[final_mask], qid[final_mask]\n",
    "\n",
    "X_balanced_small, y_balanced_small, qid_balanced_small = balance_irrelevant(\n",
    "    X_train_small, y_train_small, qid_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62655\n",
      "26531\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train_small))\n",
    "print(len(y_balanced_small))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifying ranking success with NDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDCG explanation : https://en.wikipedia.org/wiki/Discounted_cumulative_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(relevances, rank=10):\n",
    "    \"\"\"Discounted cumulative gain at rank (DCG)\"\"\"\n",
    "    relevances = np.asarray(relevances)[:rank]\n",
    "    n_relevances = len(relevances)\n",
    "    if n_relevances == 0:\n",
    "        return 0.\n",
    "\n",
    "    discounts = np.log2(np.arange(n_relevances) + 2)\n",
    "    return np.sum(relevances / discounts)\n",
    " \n",
    "def ndcg(relevances, rank=10):\n",
    "    \"\"\"Normalized discounted cumulative gain (NDGC)\"\"\"\n",
    "    best_dcg = dcg(sorted(relevances, reverse=True), rank)\n",
    "    if best_dcg == 0:\n",
    "        return 0.\n",
    "\n",
    "    return dcg(relevances, rank) / best_dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8625300399291566"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg([2, 4, 0, 1, 1, 0, 0], rank=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13201850690866795"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg([0, 0, 0, 1, 1, 2, 4], rank=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg([0, 0, 0, 1, 1, 2, 4], rank=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg([4, 2, 1, 1, 0, 0, 0], rank=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9795191506818377"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_ndcg(y_true, y_pred, query_ids, rank=10):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    query_ids = np.asarray(query_ids)\n",
    "    # assume query_ids are sorted\n",
    "    ndcg_scores = []\n",
    "    previous_qid = query_ids[0]\n",
    "    previous_loc = 0\n",
    "    for loc, qid in enumerate(query_ids):\n",
    "        if previous_qid != qid:\n",
    "            chunk = slice(previous_loc, loc)\n",
    "            ranked_relevances = y_true[chunk][np.argsort(y_pred[chunk])[::-1]]\n",
    "            ndcg_scores.append(ndcg(ranked_relevances, rank=rank))\n",
    "            previous_loc = loc\n",
    "        previous_qid = qid\n",
    "\n",
    "    chunk = slice(previous_loc, loc + 1)\n",
    "    ranked_relevances = y_true[chunk][np.argsort(y_pred[chunk])[::-1]]\n",
    "    ndcg_scores.append(ndcg(ranked_relevances, rank=rank))\n",
    "    return np.mean(ndcg_scores)\n",
    "\n",
    "mean_ndcg([4, 3, 1, 4, 3], [4, 0, 1, 4, 2], [0, 0, 0, 2, 2], rank=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation(model, X, y, qid):\n",
    "    tic = time()\n",
    "    y_predicted = model.predict(X)\n",
    "    prediction_time = time() - tic\n",
    "    print(\"Prediction time: {:.3f}s\".format(prediction_time))\n",
    "    print(\"NDCG@5 score: {:.3f}\".format(\n",
    "    mean_ndcg(y, y_predicted, qid, rank=5)))\n",
    "    print(\"NDCG@10 score: {:.3f}\".format(\n",
    "    mean_ndcg(y, y_predicted, qid, rank=10)))\n",
    "    print(\"NDCG score: {:.3f}\".format(\n",
    "    mean_ndcg(y, y_predicted, qid, rank=None)))\n",
    "    print(\"R2 score: {:.3f}\".format(r2_score(y, y_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ndcg_by_trees(model, X, y, qid, rank=10):\n",
    "    max_n_trees = len(model.estimators_)\n",
    "    scores = []\n",
    "    \n",
    "    if hasattr(model, 'staged_predict'):\n",
    "        # stage-wise score computation for boosted ensembles\n",
    "        n_trees = np.arange(max_n_trees) + 1\n",
    "        for y_predicted in model.staged_predict(X):\n",
    "            scores.append(mean_ndcg(y, y_predicted, qid, rank=10))\n",
    "    else:\n",
    "        # assume forest-type of tree ensemble: use a log scale to speedup\n",
    "        # the computation\n",
    "        # XXX: partial predictions could be reused\n",
    "        n_trees = np.logspace(0, np.log10(max_n_trees), 10).astype(int)\n",
    "        for j, n in enumerate(n_trees):\n",
    "            y_predicted = sub_ensemble(model, n).predict(X)\n",
    "            scores.append(mean_ndcg(y, y_predicted, qid, rank=rank))\n",
    "            \n",
    "    plt.plot(n_trees, scores)\n",
    "    plt.xlabel(\"Number of trees\")\n",
    "    plt.ylabel(\"Average NDCG@%d\" % rank)\n",
    "    _ = plt.title(\"Impact of the number of trees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premier prédicteur : ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 6s, sys: 1 s, total: 7min 7s\n",
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "etr = ExtraTreesRegressor(n_estimators=200, min_samples_split=5, random_state=1, n_jobs=-1)\n",
    "etr.fit(X_train_small, y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 1.608s\n",
      "NDCG@5 score: 0.467\n",
      "NDCG@10 score: 0.475\n",
      "NDCG score: 0.729\n",
      "R2 score: 0.138\n"
     ]
    }
   ],
   "source": [
    "print_evaluation(etr, X_test, y_test, qid_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning to rank model : LambdaMart\n",
    "\n",
    "See https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iter  Train score    Remaining                           Monitor Output \n",
      "    1       0.1784       30.46m                                         \n",
      "    2       0.2388       30.60m                                         \n",
      "    3       0.2533       30.96m                                         \n",
      "    4       0.2605       30.92m                                         \n",
      "    5       0.2656       30.96m                                         \n",
      "    6       0.2665       30.90m                                         \n",
      "    7       0.2695       30.72m                                         \n",
      "    8       0.2702       30.46m                                         \n",
      "    9       0.2706       30.51m                                         \n",
      "   10       0.2704       30.36m                                         \n",
      "   15       0.2748       29.77m                                         \n",
      "   20       0.3040       29.43m                                         \n",
      "   25       0.3060       29.01m                                         \n",
      "   30       0.3236       28.49m                                         \n",
      "   35       0.3352       27.96m                                         \n",
      "   40       0.3511       27.57m                                         \n",
      "   45       0.3644       27.04m                                         \n",
      "   50       0.3745       26.58m                                         \n",
      "   60       0.3860       25.59m                                         \n",
      "   70       0.4004       24.66m                                         \n",
      "   80       0.4105       24.00m                                         \n",
      "   90       0.4150       22.91m                                         \n",
      "  100       0.4210       21.90m                                         \n",
      "  120       0.4300       19.70m                                         \n",
      "  140       0.4428       17.57m                                         \n",
      "  160       0.4482       15.39m                                         \n",
      "  180       0.4560       13.30m                                         \n",
      "  200       0.4610       11.09m                                         \n",
      "  220       0.4661        8.86m                                         \n",
      "  240       0.4728        6.65m                                         \n",
      "  260       0.4776        4.45m                                         \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#!pip3 install pyltr\n",
    "\n",
    "from pyltr.models import LambdaMART\n",
    "\n",
    "#from sklearn.ensemble import LambdaMART\n",
    "\n",
    "lmart= LambdaMART(n_estimators=300, max_depth=3,\n",
    "                  learning_rate=0.1, random_state=1, verbose=1)\n",
    "lmart.fit(X_train_small, y_train_small, qids=qid_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_evaluation(lmart, X_test, y_test, qid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_evaluation(lmart, X_train_small, y_train_small, qid_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lmart= LambdaMART(n_estimators=300, max_depth=3,\n",
    "                  learning_rate=0.1, random_state=1, verbose=1)\n",
    "lmart.fit(X_dev, y_dev, group=qid_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_evaluation(lmart, X_test, y_test, qid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_evaluation(lmart, X_dev, y_dev, qid_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with a baseline linear regression models (with different optimizers and input scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time lr = LinearRegression().fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time y_test_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_evaluation(lr, X_test, y_test, qid_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RankSVM\n",
    "\n",
    "En vous inspirant du code ici : https://gist.github.com/coreylynch/4150976/1a2983d3a896f4caba33e1a406a5c48962e606c0\n",
    "- Programmez SVMRank\n",
    "- Evaluez le sur les données de ce notebook\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
