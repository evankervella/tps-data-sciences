{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2015, 2016 [Sebastian Raschka](sebastianraschka.com)\n",
    "\n",
    "https://github.com/rasbt/python-machine-learning-book\n",
    "\n",
    "[MIT License](https://github.com/rasbt/python-machine-learning-book/blob/master/LICENSE.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Machine Learning - Code Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Méthodes d'Ensemble : Combinaison de classifieurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added version check for recent scikit-learn 0.18 checks\n",
    "from distutils.version import LooseVersion as Version\n",
    "from sklearn import __version__ as sklearn_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pourquoi les méthodes d'ensemble marchent ?\n",
    "## Simulation de performances dans des conditions idéales (décorrélation des erreurs classifieurs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import comb\n",
    "import math\n",
    "\n",
    "def ensemble_error(n_classifier, error):\n",
    "    k_start = math.ceil(n_classifier / 2.0)\n",
    "    probs = [comb(n_classifier, k) * error**k * (1-error)**(n_classifier - k)\n",
    "             for k in range(k_start, n_classifier + 1)]\n",
    "    return sum(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import comb\n",
    "import math\n",
    "\n",
    "def ensemble_error(n_classifier, error):\n",
    "    k_start = int(math.ceil(n_classifier / 2.0))\n",
    "    probs = [comb(n_classifier, k) * error**k * (1-error)**(n_classifier - k)\n",
    "             for k in range(k_start, n_classifier + 1)]\n",
    "    return sum(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.0781269073486\n",
      "6.63850248348e-08\n"
     ]
    }
   ],
   "source": [
    "print ensemble_error(n_classifier=1, error=0.25)\n",
    "print ensemble_error(n_classifier=10, error=0.25)\n",
    "print ensemble_error(n_classifier=100, error=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "error_range = np.arange(0.0, 1.01, 0.01)\n",
    "ens_errors = [ensemble_error(n_classifier=11, error=error)\n",
    "              for error in error_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107ec4d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(error_range, \n",
    "         ens_errors, \n",
    "         label='Ensemble error', \n",
    "         linewidth=2)\n",
    "\n",
    "plt.plot(error_range, \n",
    "         error_range, \n",
    "         linestyle='--',\n",
    "         label='Base error',\n",
    "         linewidth=2)\n",
    "\n",
    "plt.xlabel('Base error')\n",
    "plt.ylabel('Base/Ensemble error')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/ensemble_err.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Une méthode simple de vote majoritaire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implémentation de la classe Vote Majoritaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Completez les fonctions predict et predict_proba de MajorityVoteClassifier\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import six\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "\n",
    "class MajorityVoteClassifier(BaseEstimator, \n",
    "                             ClassifierMixin):\n",
    "    \"\"\" A majority vote ensemble classifier\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    classifiers : array-like, shape = [n_classifiers]\n",
    "      Different classifiers for the ensemble\n",
    "\n",
    "    vote : str, {'classlabel', 'probability'} (default='label')\n",
    "      If 'classlabel' the prediction is based on the argmax of\n",
    "        class labels. Else if 'probability', the argmax of\n",
    "        the sum of probabilities is used to predict the class label\n",
    "        (recommended for calibrated classifiers).\n",
    "\n",
    "    weights : array-like, shape = [n_classifiers], optional (default=None)\n",
    "      If a list of `int` or `float` values are provided, the classifiers\n",
    "      are weighted by importance; Uses uniform weights if `weights=None`.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, classifiers, vote='classlabel', weights=None):\n",
    "\n",
    "        self.classifiers = classifiers\n",
    "        self.named_classifiers = {key: value for key, value\n",
    "                                  in _name_estimators(classifiers)}\n",
    "        self.vote = vote\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit classifiers.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Matrix of training samples.\n",
    "\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Vector of target class labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        if self.vote not in ('probability', 'classlabel'):\n",
    "            raise ValueError(\"vote must be 'probability' or 'classlabel'\"\n",
    "                             \"; got (vote=%r)\"\n",
    "                             % self.vote)\n",
    "\n",
    "        if self.weights and len(self.weights) != len(self.classifiers):\n",
    "            raise ValueError('Number of classifiers and weights must be equal'\n",
    "                             '; got %d weights, %d classifiers'\n",
    "                             % (len(self.weights), len(self.classifiers)))\n",
    "\n",
    "        # Use LabelEncoder to ensure class labels start with 0, which\n",
    "        # is important for np.argmax call in self.predict\n",
    "        self.lablenc_ = LabelEncoder()\n",
    "        self.lablenc_.fit(y)\n",
    "        self.classes_ = self.lablenc_.classes_\n",
    "        self.classifiers_ = []\n",
    "        for clf in self.classifiers:\n",
    "            fitted_clf = clone(clf).fit(X, self.lablenc_.transform(y))\n",
    "            self.classifiers_.append(fitted_clf)\n",
    "        return self\n",
    "        \n",
    "       \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\" Predict class probabilities for X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        avg_proba : array-like, shape = [n_samples, n_classes]\n",
    "            Weighted average probability for each class per sample.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        predicted_proba = []\n",
    "        for clf in self.classifiers_:\n",
    "            predicted_proba.append(clf.predict_proba(X))\n",
    "        avg_proba = np.average(predicted_proba, axis=0)\n",
    "        return avg_proba\n",
    "    \n",
    "        #Completez la fonction. Vous pouvez utiliser \n",
    "        #[clf.predict_proba(X) for clf in self.classifiers_]\n",
    "        #pour obtenir les predictions des classifieurs\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict class labels for X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Matrix of training samples.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        maj_vote : array-like, shape = [n_samples]\n",
    "            Predicted class labels.\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        # Methode probabiliste\n",
    "        if self.vote == 'probability':\n",
    "            maj_vote = np.argmax(self.predict_proba(X), axis = 1)\n",
    "            return maj_vote\n",
    "    \n",
    "        # Methode vote\n",
    "        elif self.vote == 'classlabel':\n",
    "            predicted_class = []\n",
    "            for clf in self.classifiers_:\n",
    "                index_predicted_class = clf.predict(X)\n",
    "                \n",
    "            b = np.bincount(predicted_class)\n",
    "            maj_vote = np.argmax(b)\n",
    "            return maj_vote\n",
    "        \n",
    "        #Completez la fonction. Vous pouvez utiliser \n",
    "        #[clf.predict(X) for clf in self.classifiers_]\n",
    "        #pour obtenir les predictions des classifieurs\n",
    "\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\" Get classifier parameter names for GridSearch\"\"\"\n",
    "        if not deep:\n",
    "            return super(MajorityVoteClassifier, self).get_params(deep=False)\n",
    "        else:\n",
    "            out = self.named_classifiers.copy()\n",
    "            for name, step in six.iteritems(self.named_classifiers):\n",
    "                for key, value in six.iteritems(step.get_params(deep=True)):\n",
    "                    out['%s__%s' % (name, key)] = value\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinaison de différents algorithmes par vote majoritaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "if Version(sklearn_version) < '0.18':\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "else:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[50:, [1, 2]], iris.target[50:]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "       train_test_split(X, y, \n",
    "                        test_size=0.5, \n",
    "                        random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Performances des modèles isolés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation:\n",
      "\n",
      "ROC AUC: 0.92 (+/- 0.20) [Logistic Regression]\n",
      "ROC AUC: 0.92 (+/- 0.15) [Decision Tree]\n",
      "ROC AUC: 0.93 (+/- 0.10) [KNN]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.pipeline import Pipeline\n",
    "if Version(sklearn_version) < '0.18':\n",
    "    from sklearn.cross_validation import cross_val_score\n",
    "else:\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf1 = LogisticRegression(penalty='l2', \n",
    "                          C=0.001,\n",
    "                          random_state=0)\n",
    "\n",
    "clf2 = DecisionTreeClassifier(max_depth=1,\n",
    "                              criterion='entropy',\n",
    "                              random_state=0)\n",
    "\n",
    "clf3 = KNeighborsClassifier(n_neighbors=1,\n",
    "                            p=2,\n",
    "                            metric='minkowski')\n",
    "\n",
    "pipe1 = Pipeline([['sc', StandardScaler()],\n",
    "                  ['clf', clf1]])\n",
    "pipe3 = Pipeline([['sc', StandardScaler()],\n",
    "                  ['clf', clf3]])\n",
    "\n",
    "clf_labels = ['Logistic Regression', 'Decision Tree', 'KNN']\n",
    "\n",
    "print('10-fold cross validation:\\n')\n",
    "for clf, label in zip([pipe1, clf2, pipe3], clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=10,\n",
    "                             scoring='roc_auc')\n",
    "    print(\"ROC AUC: %0.2f (+/- %0.2f) [%s]\"\n",
    "          % (scores.mean(), scores.std(), label))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance de la combinaison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez MajorityVoteClassifier pour combiner les 3 classifieurs précédents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.83758476  0.16241524]\n",
      " [ 0.19106267  0.80893733]\n",
      " [ 0.83452208  0.16547792]\n",
      " [ 0.83414448  0.16585552]\n",
      " [ 0.19355175  0.80644825]\n",
      " [ 0.83509608  0.16490392]\n",
      " [ 0.83528639  0.16471361]\n",
      " [ 0.19296252  0.80703748]\n",
      " [ 0.83625306  0.16374694]\n",
      " [ 0.1921952   0.8078048 ]\n",
      " [ 0.83644028  0.16355972]\n",
      " [ 0.19315588  0.80684412]\n",
      " [ 0.19238854  0.80761146]\n",
      " [ 0.83567307  0.16432693]\n",
      " [ 0.83452208  0.16547792]\n",
      " [ 0.19315284  0.80684716]\n",
      " [ 0.8339511   0.1660489 ]\n",
      " [ 0.19353044  0.80646956]\n",
      " [ 0.83318065  0.16681935]\n",
      " [ 0.1927722   0.8072278 ]\n",
      " [ 0.19182679  0.80817321]\n",
      " [ 0.52859806  0.47140194]\n",
      " [ 0.19411665  0.80588335]\n",
      " [ 0.1950744   0.8049256 ]\n",
      " [ 0.8373915   0.1626085 ]\n",
      " [ 0.1950744   0.8049256 ]\n",
      " [ 0.83376077  0.16623923]\n",
      " [ 0.1912651   0.8087349 ]\n",
      " [ 0.19201404  0.80798596]\n",
      " [ 0.83585423  0.16414577]\n",
      " [ 0.83662446  0.16337554]\n",
      " [ 0.83414143  0.16585857]\n",
      " [ 0.83451904  0.16548096]\n",
      " [ 0.83549495  0.16450505]\n",
      " [ 0.52743476  0.47256524]\n",
      " [ 0.19162434  0.80837566]\n",
      " [ 0.83413839  0.16586161]\n",
      " [ 0.83298727  0.16701273]\n",
      " [ 0.1946846   0.8053154 ]\n",
      " [ 0.19487493  0.80512507]\n",
      " [ 0.83356131  0.16643869]\n",
      " [ 0.83394806  0.16605194]\n",
      " [ 0.19430394  0.80569606]\n",
      " [ 0.19258494  0.80741506]\n",
      " [ 0.8343348   0.1656652 ]\n",
      " [ 0.19181766  0.80818234]\n",
      " [ 0.83567003  0.16432997]\n",
      " [ 0.19125902  0.80874098]\n",
      " [ 0.83644637  0.16355363]\n",
      " [ 0.83549191  0.16450809]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-74e713ec529e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-03c4cc27ec21>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mmaj_vote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmaj_vote\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \"\"\"\n\u001b[0;32m--> 963\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "classifiers = [pipe1, clf2, pipe3]\n",
    "test1 = MajorityVoteClassifier([pipe1, clf2, pipe3], 'classlabel')\n",
    "test1.fit(X_train, y_train)\n",
    "print test1.predict_proba(X_train)\n",
    "print test1.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquez la fonction get_params() sur votre MajorityVoteClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decisiontreeclassifier': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=1,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "             splitter='best'),\n",
       " 'decisiontreeclassifier__class_weight': None,\n",
       " 'decisiontreeclassifier__criterion': 'entropy',\n",
       " 'decisiontreeclassifier__max_depth': 1,\n",
       " 'decisiontreeclassifier__max_features': None,\n",
       " 'decisiontreeclassifier__max_leaf_nodes': None,\n",
       " 'decisiontreeclassifier__min_impurity_decrease': 0.0,\n",
       " 'decisiontreeclassifier__min_impurity_split': None,\n",
       " 'decisiontreeclassifier__min_samples_leaf': 1,\n",
       " 'decisiontreeclassifier__min_samples_split': 2,\n",
       " 'decisiontreeclassifier__min_weight_fraction_leaf': 0.0,\n",
       " 'decisiontreeclassifier__presort': False,\n",
       " 'decisiontreeclassifier__random_state': 0,\n",
       " 'decisiontreeclassifier__splitter': 'best',\n",
       " 'pipeline-1': Pipeline(memory=None,\n",
       "      steps=[['sc', StandardScaler(copy=True, with_mean=True, with_std=True)], ['clf', LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False)]]),\n",
       " 'pipeline-1__clf': LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'pipeline-1__clf__C': 0.001,\n",
       " 'pipeline-1__clf__class_weight': None,\n",
       " 'pipeline-1__clf__dual': False,\n",
       " 'pipeline-1__clf__fit_intercept': True,\n",
       " 'pipeline-1__clf__intercept_scaling': 1,\n",
       " 'pipeline-1__clf__max_iter': 100,\n",
       " 'pipeline-1__clf__multi_class': 'ovr',\n",
       " 'pipeline-1__clf__n_jobs': 1,\n",
       " 'pipeline-1__clf__penalty': 'l2',\n",
       " 'pipeline-1__clf__random_state': 0,\n",
       " 'pipeline-1__clf__solver': 'liblinear',\n",
       " 'pipeline-1__clf__tol': 0.0001,\n",
       " 'pipeline-1__clf__verbose': 0,\n",
       " 'pipeline-1__clf__warm_start': False,\n",
       " 'pipeline-1__memory': None,\n",
       " 'pipeline-1__sc': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'pipeline-1__sc__copy': True,\n",
       " 'pipeline-1__sc__with_mean': True,\n",
       " 'pipeline-1__sc__with_std': True,\n",
       " 'pipeline-1__steps': [['sc',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)],\n",
       "  ['clf',\n",
       "   LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "             penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "             verbose=0, warm_start=False)]],\n",
       " 'pipeline-2': Pipeline(memory=None,\n",
       "      steps=[['sc', StandardScaler(copy=True, with_mean=True, with_std=True)], ['clf', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "            weights='uniform')]]),\n",
       " 'pipeline-2__clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "            weights='uniform'),\n",
       " 'pipeline-2__clf__algorithm': 'auto',\n",
       " 'pipeline-2__clf__leaf_size': 30,\n",
       " 'pipeline-2__clf__metric': 'minkowski',\n",
       " 'pipeline-2__clf__metric_params': None,\n",
       " 'pipeline-2__clf__n_jobs': 1,\n",
       " 'pipeline-2__clf__n_neighbors': 1,\n",
       " 'pipeline-2__clf__p': 2,\n",
       " 'pipeline-2__clf__weights': 'uniform',\n",
       " 'pipeline-2__memory': None,\n",
       " 'pipeline-2__sc': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'pipeline-2__sc__copy': True,\n",
       " 'pipeline-2__sc__with_mean': True,\n",
       " 'pipeline-2__sc__with_std': True,\n",
       " 'pipeline-2__steps': [['sc',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)],\n",
       "  ['clf',\n",
       "   KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "              metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "              weights='uniform')]]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Piste d'amélioration "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NB : Bien sur vous pouvez inclure tout ceci dans un grid search pour trouver les meilleurs paramètres de l'ensemble\n",
    "\n",
    "Par exemple  :\n",
    "    \n",
    "params = {'decisiontreeclassifier__max_depth': [1, 2],\n",
    "          'pipeline-1__clf__C': [0.001, 0.1, 100.0]}\n",
    "\n",
    "grid = GridSearchCV(estimator=mv_clf,\n",
    "                    param_grid=params,\n",
    "                    cv=10,\n",
    "                    scoring='roc_auc')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best parameters: %s' % grid.best_params_)\n",
    "print('Accuracy: %.2f' % grid.best_score_)\n",
    "\n",
    "\n",
    "NB2 : la classe sklearn.ensemble.VotingClassifier vous permet aussi de faire le voting par majority rule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinaison par bagging et boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez les données de la base Iris pour tester le bagging et le boosting.\n",
    "\n",
    "Vous utiliserez respectivement BaggingClassifier et AdaBoostClassifier.\n",
    "Utilisez des arbres de décision (DecisionTreeClassifier) comme classifieurs faibles.\n",
    "Faites une gridsearch pour évaluer l'impact des different parametres.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits, load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#digits = load_digits()\n",
    "\n",
    "dataset = load_iris()\n",
    "print dataset.data.shape\n",
    "print dataset.target.shape\n",
    "\n",
    "X, y= dataset.data, dataset.target\n",
    "\n",
    "###############################################\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
